{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re, os, json\n",
    "from rxnutils import read_json, is_valid_smiles\n",
    "MODEL_NAME = \"ether0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response: str):\n",
    "    # Attempt to extract a JSON code block and parse it\n",
    "    # str format: \"<|think_start|>...<|think_end|><|answer_start|>...<|answer_end|>\"\n",
    "    # we extract the answer part\n",
    "    answer_match = re.search(r'<\\|answer_start\\|>(.*?)<\\|answer_end\\|>', response, re.DOTALL)\n",
    "    if answer_match:\n",
    "        answer = answer_match.group(1).strip()\n",
    "        return answer\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_RCR(model_name:str, log_dir:str=\"logs/RCR\"):\n",
    "    \"\"\"\n",
    "    Evaluate the reaction condition recommendation task\n",
    "    Metric: SMILES similarity\n",
    "\n",
    "    Args:\n",
    "        model_name (str): the name of the model\n",
    "        log_dir (str): the directory of the logs\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # make sure the log_dir is correct\n",
    "    if not os.path.exists(log_dir):\n",
    "        raise ValueError(f\"logs_dir {log_dir} is not correct\")\n",
    "    samples = read_json(f\"{log_dir}/{model_name}.json\")\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for sample in samples:\n",
    "        gts.append(sample['gt'])\n",
    "\n",
    "        pred_smiles = parse_response(sample['json_response'])\n",
    "        # further parsing to remove the answer tag\n",
    "        if pred_smiles.endswith(\"</answer>\"):\n",
    "            pred_smiles = pred_smiles[:-len(\"</answer>\")]\n",
    "        \n",
    "        # further parsing to extract condition smiles\n",
    "        if \">>\" in pred_smiles:\n",
    "            pred_smiles = pred_smiles.split(\">>\")[0]\n",
    "        elif '>' in pred_smiles:\n",
    "            pred_smiles = pred_smiles.split('>')[1]\n",
    "        preds.append(pred_smiles)\n",
    "\n",
    "    from evaluator import MoleculeSMILESEvaluator\n",
    "    evaluator = MoleculeSMILESEvaluator()\n",
    "    res = evaluator.evaluate(preds, gts)\n",
    "    # pretty print the res\n",
    "    print(\"exact_match: \", round(res['exact_match'], 2))\n",
    "    print(\"bleu: \", round(res['bleu'], 2))\n",
    "    print(\"levenshtein: \", round(res['levenshtein'], 2))\n",
    "    print(\"rdk_sims: \", round(res['rdk_sims'], 2))\n",
    "    print(\"maccs_sims: \", round(res['maccs_sims'], 2))\n",
    "    print(\"morgan_sims: \", round(res['morgan_sims'], 2))\n",
    "    print(\"validity: \", round(res['validity'], 2))\n",
    "    fts = (res['rdk_sims'] + res['maccs_sims'] + res['morgan_sims']) / 3\n",
    "    print(\"fts: \", round(fts * res['validity'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kakusou/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match:  0.04\n",
      "bleu:  0.06\n",
      "levenshtein:  40.22\n",
      "rdk_sims:  0.06\n",
      "maccs_sims:  0.16\n",
      "morgan_sims:  0.07\n",
      "validity:  0.94\n",
      "fts:  0.09\n"
     ]
    }
   ],
   "source": [
    "evaluate_RCR(\"ether0\", log_dir=\"logs/RCR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanism: NEPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_NEPP(model_name: str, log_dir: str):\n",
    "    \"\"\"\n",
    "    Evaluate the next element-step product prediction task\n",
    "    Metric: SMILES similarity\n",
    "\n",
    "    Args:\n",
    "        model_name (str): the name of the model\n",
    "        log_dir (str): the directory of the logs\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        raise ValueError(f\"logs_dir {log_dir} is not correct\")\n",
    "    samples = read_json(f\"{log_dir}/{model_name}.json\")\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for sample in samples:\n",
    "        gts.append(sample['gt'])\n",
    "        json_response = sample['json_response']\n",
    "        pred_smiles = parse_response(json_response)\n",
    "        preds.append(pred_smiles)\n",
    "\n",
    "    from evaluator import MoleculeSMILESEvaluator\n",
    "    evaluator = MoleculeSMILESEvaluator()\n",
    "    res = evaluator.evaluate(preds, gts)\n",
    "\n",
    "    # pretty print the res\n",
    "    print(\"exact_match: \", round(res['exact_match'], 2))\n",
    "    print(\"bleu: \", round(res['bleu'], 2))\n",
    "    print(\"levenshtein: \", round(res['levenshtein'], 2))\n",
    "    print(\"rdk_sims: \", round(res['rdk_sims'], 2))\n",
    "    print(\"maccs_sims: \", round(res['maccs_sims'], 2))\n",
    "    print(\"morgan_sims: \", round(res['morgan_sims'], 2))\n",
    "    print(\"validity: \", round(res['validity'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match:  0.02\n",
      "bleu:  0.52\n",
      "levenshtein:  24.98\n",
      "rdk_sims:  0.62\n",
      "maccs_sims:  0.61\n",
      "morgan_sims:  0.53\n",
      "validity:  0.91\n"
     ]
    }
   ],
   "source": [
    "evaluate_NEPP(\"ether0\", log_dir=\"logs/mech_task1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mechanism: MechSel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mechsel(model_name: str, logs_dir: str):\n",
    "    \"\"\"\n",
    "    Evaluate the reaction mechanism selection prediction.\n",
    "\n",
    "    Args:\n",
    "        logs_dir (str): The directory where the logs are stored.\n",
    "        model_name (str): The name of the model.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(logs_dir):\n",
    "        raise ValueError(f\"logs_dir {logs_dir} is not correct\")\n",
    "    samples = read_json(f\"{logs_dir}/{model_name}.json\")\n",
    "\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for sample in samples:\n",
    "        pred_choice = parse_response(sample['json_response'])\n",
    "        if len(pred_choice) > 1:\n",
    "            # if multiple chars, we take the first one\n",
    "            pred_choice = pred_choice[0]\n",
    "        # if pred_choice is not a valid choice, we treat it as empty\n",
    "        if pred_choice.lower() not in ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']:\n",
    "            pred_choice = \"\"\n",
    "\n",
    "        pred_choice = pred_choice.lower()\n",
    "        gt = sample['gt'].lower()\n",
    "        preds.append(pred_choice)\n",
    "        gts.append(gt)\n",
    "\n",
    "    accuracy = sum(1 for pred, gt in zip(preds, gts) if pred == gt) / len(gts)\n",
    "    print(f\"MCQ Accuracy (mean): {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MCQ Accuracy (mean): 0.27\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "evaluate_mechsel(MODEL_NAME, \"logs/mech_task2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## major product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fs(model_name: str, log_dir: str):\n",
    "    \"\"\"\n",
    "    Evaluate SMILES predictions against ground truth.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): The name of the model.\n",
    "        log_dir (str): The directory where the logs are stored.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if not os.path.exists(log_dir):\n",
    "        raise ValueError(f\"logs_dir {log_dir} is not correct\")\n",
    "    samples = read_json(f\"{log_dir}/{model_name}.json\")\n",
    "    preds = []\n",
    "    gts = []\n",
    "    for sample in samples:\n",
    "        ## parse the gt\n",
    "        try:\n",
    "            gt = sample['products']\n",
    "        except:\n",
    "            gt = json.loads(sample['gt']).get(\"Major Product\")\n",
    "        if isinstance(gt, list):\n",
    "            gt = '.'.join(gt)\n",
    "        gts.append(gt)\n",
    "\n",
    "        ## parse the pred\n",
    "        pred_smiles = parse_response(sample['json_response'])\n",
    "        preds.append(pred_smiles)\n",
    "\n",
    "    from evaluator import MoleculeSMILESEvaluator\n",
    "    evaluator = MoleculeSMILESEvaluator()\n",
    "    res = evaluator.evaluate(preds, gts)\n",
    "\n",
    "    print(\"exact_match: \", round(res['exact_match'], 2))\n",
    "    print(\"bleu: \", round(res['bleu'], 2))\n",
    "    print(\"levenshtein: \", round(res['levenshtein'], 2))\n",
    "    print(\"rdk_sims: \", round(res['rdk_sims'], 2))\n",
    "    print(\"maccs_sims: \", round(res['maccs_sims'], 2))\n",
    "    print(\"morgan_sims: \", round(res['morgan_sims'], 2))\n",
    "    print(\"validity: \", round(res['validity'], 2))\n",
    "    fts = (res['rdk_sims'] + res['maccs_sims'] + res['morgan_sims']) / 3\n",
    "    print(\"fts: \", round(fts * res['validity'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match:  0.74\n",
      "bleu:  0.77\n",
      "levenshtein:  12.56\n",
      "rdk_sims:  0.83\n",
      "maccs_sims:  0.86\n",
      "morgan_sims:  0.82\n",
      "validity:  0.92\n",
      "fts:  0.77\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "evaluate_fs(MODEL_NAME, \"logs/fs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## by product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_raw_response(raw_response: str, field: str) -> str:\n",
    "    \"\"\"从原始响应字符串中提取指定字段的值\n",
    "    \n",
    "    Args:\n",
    "        raw_response: 可能包含 JSON 块或键值对的原始字符串\n",
    "        field: 需要提取的字段名（如 \"Byproduct(s)\"）\n",
    "    \n",
    "    Returns:\n",
    "        提取到的字段值字符串，未找到则返回空字符串\n",
    "    \"\"\"\n",
    "    \n",
    "    # 改进点 1: 更健壮的 JSON 块检测（支持不同格式的代码块）\n",
    "    json_block_match = re.search(\n",
    "        r'```(?:json)?\\s*({.*?})\\s*```',  # 匹配可选的 json 标记和任意空格\n",
    "        raw_response, \n",
    "        flags=re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    \n",
    "    if json_block_match:\n",
    "        try:\n",
    "            # 改进点 2: 更严格的 JSON 解析（处理嵌套结构）\n",
    "            json_str = json_block_match.group(1).strip()\n",
    "            data = json.loads(json_str)\n",
    "            \n",
    "            # 改进点 3: 处理数组型结果（如 [\"HCl\", \"H2O\"]）\n",
    "            if value := data.get(field):\n",
    "                if isinstance(value, list):\n",
    "                    return \", \".join(map(str, value))\n",
    "                return str(value)\n",
    "        except (json.JSONDecodeError, AttributeError):\n",
    "            pass  # 解析失败则继续尝试其他方法\n",
    "\n",
    "    # 改进点 4: 更灵活的正则匹配（处理多种引号和转义）\n",
    "    escaped_field = re.escape(field)  # 转义特殊字符如括号\n",
    "    \n",
    "    # 模式 1: 匹配双引号字符串（允许转义双引号）\n",
    "    pattern = fr'\"{escaped_field}\":\\s*\"((?:\\\\\"|[^\"])*)\"'\n",
    "    if match := re.search(pattern, raw_response):\n",
    "        try:\n",
    "            # 使用 JSON 解析处理转义字符\n",
    "            return json.loads(f'\"{match.group(1)}\"')\n",
    "        except json.JSONDecodeError:\n",
    "            return match.group(1).replace(r'\\\"', '\"')\n",
    "    \n",
    "    # 模式 2: 匹配单引号字符串（允许转义单引号）\n",
    "    pattern = fr'\"{escaped_field}\":\\s*\\'((?:\\\\\\'|[^\\'])*)\\''\n",
    "    if match := re.search(pattern, raw_response):\n",
    "        return match.group(1).replace(r\"\\'\", \"'\")\n",
    "    \n",
    "    # 改进点 5: 匹配无引号的值（如数值或布尔值）\n",
    "    pattern = fr'\"{escaped_field}\":\\s*([^,\\s}}]+)'\n",
    "    if match := re.search(pattern, raw_response):\n",
    "        return match.group(1).strip()\n",
    "\n",
    "    return \"\"  # 所有模式均未匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fs_byproduct(model_name, log_dir:str=\"logs/fs\"):\n",
    "    samples = read_json(f\"{log_dir}/{model_name}.json\")\n",
    "    preds = []\n",
    "    gts = []\n",
    "    \n",
    "    for sample in samples:\n",
    "        ## parse the gt\n",
    "        try:\n",
    "            gt = sample['byproducts']\n",
    "        except:\n",
    "            gt = json.loads(sample['gt'])[\"Byproduct(s)\"]\n",
    "        if len(gt) == 0:  # if no byproducts, skip the sample\n",
    "            continue\n",
    "        if isinstance(gt, list):\n",
    "            gt = '.'.join(gt)\n",
    "\n",
    "        ## parse the pred\n",
    "        if isinstance(sample['json_response'], dict):\n",
    "            if \"Byproduct(s)\" in sample['json_response']:\n",
    "                pred_smiles = sample['json_response'][\"Byproduct(s)\"]\n",
    "            else:\n",
    "                pred_smiles = parse_raw_response(sample['raw_response'], \"Byproduct(s)\")\n",
    "        else:\n",
    "            try:\n",
    "                pred_smiles = parse_raw_response(sample['raw_response'], \"Byproduct(s)\")\n",
    "            except:\n",
    "                pred_smiles = \"\"\n",
    "\n",
    "        gts.append(gt)\n",
    "        preds.append(pred_smiles)\n",
    "\n",
    "    from evaluator import MoleculeSMILESEvaluator\n",
    "    evaluator = MoleculeSMILESEvaluator()\n",
    "    res = evaluator.evaluate(preds, gts)\n",
    "    print(\"exact_match: \", round(res['exact_match'], 2))\n",
    "    print(\"bleu: \", round(res['bleu'], 2))\n",
    "    print(\"levenshtein: \", round(res['levenshtein'], 2))\n",
    "    print(\"rdk_sims: \", round(res['rdk_sims'], 2))\n",
    "    print(\"maccs_sims: \", round(res['maccs_sims'], 2))\n",
    "    print(\"morgan_sims: \", round(res['morgan_sims'], 2))\n",
    "    print(\"validity: \", round(res['validity'], 2))\n",
    "    fts = (res['rdk_sims'] + res['maccs_sims'] + res['morgan_sims']) / 3\n",
    "    print(\"fts: \", round(fts * res['validity'], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match:  0.0\n",
      "bleu:  0.0\n",
      "levenshtein:  0.0\n",
      "rdk_sims:  0.0\n",
      "maccs_sims:  0.0\n",
      "morgan_sims:  0.0\n",
      "validity:  0.0\n",
      "fts:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "evaluate_fs_byproduct(MODEL_NAME, \"logs/fs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exact_match:  0.0\n",
      "bleu:  0.5\n",
      "levenshtein:  25.0\n",
      "rdk_sims:  0.51\n",
      "maccs_sims:  0.57\n",
      "morgan_sims:  0.43\n",
      "validity:  0.87\n",
      "fts:  0.44\n"
     ]
    }
   ],
   "source": [
    "def evaluate_retro(model_name: str, log_dir: str):\n",
    "    if not os.path.exists(log_dir):\n",
    "        raise ValueError(f\"logs_dir {log_dir} is not correct\")\n",
    "    samples = read_json(f\"{log_dir}/{model_name}.json\")\n",
    "    preds = []\n",
    "    gts = []\n",
    "\n",
    "    for sample in samples:\n",
    "        ## parse the gt\n",
    "        gt = sample['reactants']\n",
    "        if len(gt) == 0:\n",
    "            continue\n",
    "        if isinstance(gt, list):\n",
    "            gt = '.'.join(gt)\n",
    "        gts.append(gt)\n",
    "\n",
    "        ## parse the pred\n",
    "        pred_smiles = parse_response(sample['json_response'])\n",
    "        preds.append(pred_smiles)\n",
    "\n",
    "    from evaluator import MoleculeSMILESEvaluator\n",
    "    evaluator = MoleculeSMILESEvaluator()\n",
    "    res = evaluator.evaluate(preds, gts)\n",
    "\n",
    "    print(\"exact_match: \", round(res['exact_match'], 2))\n",
    "    print(\"bleu: \", round(res['bleu'], 2))\n",
    "    print(\"levenshtein: \", round(res['levenshtein'], 2))\n",
    "    print(\"rdk_sims: \", round(res['rdk_sims'], 2))\n",
    "    print(\"maccs_sims: \", round(res['maccs_sims'], 2))\n",
    "    print(\"morgan_sims: \", round(res['morgan_sims'], 2))\n",
    "    print(\"validity: \", round(res['validity'], 2))\n",
    "    fts = (res['rdk_sims'] + res['maccs_sims'] + res['morgan_sims']) / 3\n",
    "    print(\"fts: \", round(fts * res['validity'], 2))\n",
    "\n",
    "evaluate_retro(MODEL_NAME, \"logs/retro\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
